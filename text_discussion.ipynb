{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 1 deleted discussions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Problem formulation**\n",
    "\n",
    "Construct different multiple linear regression (MLR) models on the training data, consisting of 733 workers to examine the relationship between some of the independent variables, with years of experience and years of education as the base, and the monthly wage. Test the models' accuracy on the test data including of 183 workers.\n",
    "\n",
    "There are a total of 15 independent variables in the dataset, including experience and education. Identify missing variables that potentially cause omitted variable bias (OVB) and incorporate them into the base model. Evaluate the fit of the new model and check for multicollinearity\n",
    "\n",
    "Consider other potential methods of model formulations and independent variables that could improve the model's fit and predictive accuracy.\n",
    "\n",
    "**4. Data cleaning**\n",
    "\n",
    "We consider two approaches to data cleaning. The first one is to drop datas consist of null values only to the extent of dependent variables that we decide to use in the model formulation. This way, minimum number of data will be removed, which both helps remain as much data as possible, but still ensure consistency and integrity in the analysis. However, we find it challenging to figure out which dependent variables will be used in the formulation in the first stage. Therefore we come up with the second approach of dropping all datas that one or more of the dependent variables are null. This way, 203 datas of the train dataset and 56 datas of the test data set were removed. We acknowledge that reducing the size of the dataset significantly may impact its representativeness of the population, however as a trade-off, it would also prevent biases or inaccuracies in the regression results that the original one may have caused. Hence, the analysis ensures that model outputs are based fully on complete data, enhancing reliability of the insights into the relationships between these variables. For future research purposes, additional and complete data connection, together with research and analysis should be conducted to give timely and optimal findings of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2 deleted discussions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residuals vs fitted values plot shows no clear pattern in the mean, i.e. the errors seem to average close to 0 for most fitted values, as confirmed by the LOESS curve (apart from a mild dip in the middle). The residuals vs each predictor show that **E**$(e|X) = 0$ appears to hold for most value of $X$. Thus, the linear model seems a reasonable fit for the wage data.\n",
    "\n",
    "However, there is evidence that the variance of residuals increases slightly for higher fitted values. This is visible in the squared residuals plot, where spread is larger at the extremes. Hence, the assumption of constant variance may not hold, and inference may benefit from using heteroskedasticity-robust standard errors.\n",
    "\n",
    "The scatter plots of wage against each predictor (in blue), overlaid with fitted values (in orange), offer additional insights:\n",
    "\n",
    "For **education**, the orange predicted values track the increasing trend in wage with rising education, though they tend to underpredict for higher earners.\n",
    "\n",
    "For **experience**, a similar pattern is observed: predictions follow the general shape of the data but fail to capture some curvature or variance at higher experience levels. These plots suggest that the model captures the main linear trend well, though it might benefit from polynomial or interaction terms for more accuracy. \n",
    "\n",
    "Regarding the other MLR LSA:\n",
    "\n",
    "**LSA 2** requires **E**$(e|X) = 0$. While the resiual plots support this assumption, it may still be violated due to **omitted variable bias**. For instance, IQ and KWW, which show a positive correlation with wage and likely correlate with educ, are not included in this model. This may bias the coefficient estimates for educ.\n",
    "\n",
    "**LSA 3** assumes that the observations are i.i.d. As we lack temporal or cluster structure in the data, we proceed under this assumption.\n",
    "\n",
    "**LSA 4** concerns finite $4^{th}$ moments. Variables such as exper, educ and wage are bounded in practice and show no severe outliers, so this assumption is reasonably satisfied. \n",
    "\n",
    "**LSA 5** (no perfect multicollinearity): educ and exper and only moderately correlated (~0.55), which is well below the threshold for concern. Hence, no multicollinearity issues are detected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 3 deleted discussions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original reduced MLR was esimated as: $\\hat{Wage} = -201.45 + 72.88 \\times \\mbox{educ} + 15.68 \\times \\mbox{exper}$. 95% confidence intervals for the two slopes are: $(58.65, 87.12)$ and $(8.65,22.71)$.\n",
    "\n",
    "The new MLR is estimated as: $\\hat{Wage} = -298.65 + 11.11 \\times \\mbox{KWW} + 54.23 \\times \\mbox{educ} + 11.32 \\times \\mbox{exper} $. 95% confidence intervals for the three slopes are: $(7.08,15.13), (38.72,69.75)$ and $(4.25,18.40)$.\n",
    "\n",
    "The estimated effect of educ in the three variable MLR has dropped to be lower than the 95% CI from the two-variable MLR. Clearly, KWW was causing some OVB in this estimated effect in the two variable MLR.\n",
    "\n",
    "The estimated effect of exper has become more negative, however the two 95% CIs have a large overlap and the difference in estimate here can probably be put down to simply estimation error, rather than OVB. In other words, though KWW could have caused some OVB in the two variable MLR for educ, the large standard error on this effect makes it difficult to assess the level of OVB caused, or even if any was apparent."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
